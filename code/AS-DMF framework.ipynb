{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib,copy,alipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from alipy import ToolBox\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import array,loadtxt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import model_selection,metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,confusion_matrix,f1_score\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from alipy.query_strategy import QueryInstanceGraphDensity,QueryInstanceDensityWeighted,QueryInstanceUncertainty\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the DMF model\n",
    "def stmodel(num):\n",
    "    sclf = RandomForestClassifier(oob_score=True,n_jobs=-1)\n",
    "    sxgb = XGBClassifier(eval_metric=['logloss','auc','error'],max_depth=20,n_jobs=-1)\n",
    "    sgnb = GaussianNB()\n",
    "    pipe1 = make_pipeline(ColumnSelector(cols=range(num)),sclf)\n",
    "\n",
    "    pipe2 = make_pipeline(ColumnSelector(cols=range(num)),sxgb)\n",
    "\n",
    "    pipe3 = make_pipeline(ColumnSelector(cols=range(num)),sgnb)\n",
    "\n",
    "    stack = StackingClassifier(classifiers=[pipe1,pipe2,pipe3], meta_classifier=LogisticRegression(solver=\"lbfgs\"))\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d7afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the reduction sample set and label \n",
    "X = np.loadtxt('reduction50.csv')\n",
    "y = np.loadtxt('y_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083aa022",
   "metadata": {},
   "source": [
    "# uncertainty sampling (UNSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9326c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query ToolBox and set the saveing_path\n",
    "alibox = ToolBox(X=X, y=y, query_type='AllLabels', saving_path='./')\n",
    "            \n",
    "# Split data\n",
    "alibox.split_AL(test_ratio=0.3, initial_label_rate=0.001, split_count=20)\n",
    "\n",
    "# Use the DMF classifier with 10 features\n",
    "model  = stmodel(10)\n",
    "            \n",
    "# The cost budget is 100 times querying\n",
    "stopping_criterion = alibox.get_stopping_criterion('num_of_queries', 100)\n",
    "\n",
    "def main_loop(alibox, strategy, round):\n",
    "    # Get the data split of one fold experiment\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox.get_split(round)\n",
    "    # Get intermediate results saver for one fold experiment\n",
    "    saver = alibox.get_stateio(round)\n",
    "\n",
    "    # Set initial performance point\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = alibox.calc_performance_metric(y_true=y[test_idx],\n",
    "                                              y_pred=pred,\n",
    "                                              performance_metric='accuracy_score')\n",
    "    saver.set_initial_point(accuracy)\n",
    "            \n",
    "    # If the stopping criterion is simple, such as query 100 times. Use `for i in range(100):` is ok.\n",
    "    while not stopping_criterion.is_stop():\n",
    "        # Select a subset of Uind according to the query strategy\n",
    "        # Passing model=None to use the default model for evaluating the committees' disagreement\n",
    "        select_ind = strategy.select(label_index=label_ind, unlabel_index=unlab_ind, batch_size=1)\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "\n",
    "        # Update model and calc performance according to the model you are using\n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = alibox.calc_performance_metric(y_true=y[test_idx],\n",
    "                                                y_pred=pred,\n",
    "                                                performance_metric='accuracy_score')\n",
    "\n",
    "        # Save intermediate results to file\n",
    "        st = alibox.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "\n",
    "        # Passing the current progress to stopping criterion object\n",
    "        stopping_criterion.update_information(saver)\n",
    "    # Reset the progress in stopping criterion object\n",
    "    stopping_criterion.reset()\n",
    "    return saver    \n",
    "\n",
    "unc_result = []\n",
    " \n",
    "for round in range(10):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox.get_split(round)\n",
    "            \n",
    "    # Use defined strategy\n",
    "    unc = alibox.get_query_strategy(strategy_name=\"QueryInstanceUncertainty\")\n",
    "    unc_result.append(copy.deepcopy(main_loop(alibox, unc, round)))\n",
    "\n",
    "#get the query results\n",
    "analyser = alibox.get_experiment_analyser(x_axis='num_of_queries')\n",
    "analyser.add_method(method_name='UNSM', method_results=unc_result)\n",
    "print(analyser)\n",
    "# show the figure\n",
    "analyser.plot_learning_curves(title='Uncertainty Sampling', std_area=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28006f9e",
   "metadata": {},
   "source": [
    "# UNSM+Graph density (UNGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94466fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alibox1 = ToolBox(X=X, y=y, query_type='AllLabels', saving_path='./')\n",
    "\n",
    "alibox1.split_AL(test_ratio=0.3, initial_label_rate=0.001, split_count=20)\n",
    "\n",
    "model  = stmodel(50)    \n",
    "\n",
    "stopping_criterion = alibox1.get_stopping_criterion('num_of_queries', 100)\n",
    "            \n",
    "def main_loop(alibox1, strategy, round):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox1.get_split(round)\n",
    "    saver = alibox1.get_stateio(round)\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = alibox1.calc_performance_metric(y_true=y[test_idx],\n",
    "                                              y_pred=pred,\n",
    "                                              performance_metric='accuracy_score')\n",
    "    saver.set_initial_point(accuracy)     \n",
    "\n",
    "    while not stopping_criterion.is_stop():\n",
    "        select_ind = strategy.select(label_index=label_ind, unlabel_index=unlab_ind, batch_size=1)\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "\n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = alibox1.calc_performance_metric(y_true=y[test_idx],\n",
    "                                                y_pred=pred,\n",
    "                                                performance_metric='accuracy_score')\n",
    "\n",
    "        st = alibox1.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "        stopping_criterion.update_information(saver)\n",
    "        \n",
    "    stopping_criterion.reset()\n",
    "    return saver\n",
    "\n",
    "denG_result = []\n",
    "\n",
    "for round in range(5):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox1.get_split(round)\n",
    "            \n",
    "    # Use UNSM to find the most uncerain points\n",
    "    unc1 = alibox1.get_query_strategy(strategy_name=\"QueryInstanceUncertainty\")\n",
    "    denG_result.append(copy.deepcopy(main_loop(alibox1, unc1, round)))\n",
    "    \n",
    "for round in range(5,10):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox1.get_split(round)\n",
    "            \n",
    "    # Use Graph Density to uery dense samle points\n",
    "    denG = alibox1.get_query_strategy(strategy_name=\"QueryInstanceGraphDensity\", train_idx=train_idx)\n",
    "\n",
    "    denG_result.append(copy.deepcopy(main_loop(alibox1, denG, round)))\n",
    "\n",
    "analyser1 = alibox1.get_experiment_analyser(x_axis='num_of_queries')\n",
    "analyser1.add_method(method_name='UNGD', method_results=denG_result)\n",
    "print(analyser1)\n",
    "analyser1.plot_learning_curves(title='Uncertainty & GraphDensity', std_area=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3576a4b",
   "metadata": {},
   "source": [
    "# UNSM + Information density (UNID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alibox2= ToolBox(X=X, y=y, query_type='AllLabels', saving_path='./')\n",
    "\n",
    "alibox2.split_AL(test_ratio=0.3, initial_label_rate=0.001, split_count=20)\n",
    "\n",
    "model = stmodel(10)\n",
    "\n",
    "stopping_criterion = alibox2.get_stopping_criterion('num_of_queries',100)\n",
    "     \n",
    "denWStrategy = alibox2.get_query_strategy(strategy_name='QueryInstanceDensityWeighted',\n",
    "                                               uncertainty_meansure='entropy')\n",
    "denW_result = []\n",
    "\n",
    "for round in range(10):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox2.get_split(round)\n",
    "    saver = alibox2.get_stateio(round)\n",
    "\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = alibox2.calc_performance_metric(y_true=y[test_idx],y_pred=pred,\n",
    "                                                performance_metric='accuracy_score')\n",
    "    saver.set_initial_point(accuracy)\n",
    "    \n",
    "    while not stopping_criterion.is_stop():\n",
    "        select_ind = denWStrategy.select(label_ind, unlab_ind, model=model, batch_size=1)\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "     \n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = alibox2.calc_performance_metric(y_true=y[test_idx],y_pred=pred,\n",
    "                                                performance_metric='accuracy_score')\n",
    "     \n",
    "        st = alibox2.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "        saver.save()\n",
    "        stopping_criterion.update_information(saver)\n",
    "        \n",
    "    stopping_criterion.reset()\n",
    "    denW_result.append(copy.deepcopy(saver))\n",
    "\n",
    "analyser2 = alibox2.get_experiment_analyser(x_axis='num_of_queries')\n",
    "analyser2.add_method(method_name='Uncertainty & DensityWeighted', method_results=denW_result)\n",
    "print(analyser2)\n",
    "analyser2.plot_learning_curves(title='UNID', std_area=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alipy.experiment import ExperimentAnalyser\n",
    "# get the query results\n",
    "anal1 = ExperimentAnalyser(x_axis='num_of_queries')\n",
    "anal1.add_method('UNSM', unc_result)\n",
    "anal1.add_method('UNID',denW_result)\n",
    "anal1.add_method('UNGD', denG_result)\n",
    "# set plot parameters\n",
    "anal1.plot_learning_curves(title='F10 - Learning curves', std_area=True,show=False)\n",
    "plt.title('F10 - Learning curves',fontproperties='Times New Roman',fontsize=14)\n",
    "plt.yticks(fontproperties='Times New Roman',fontsize=12)\n",
    "plt.xticks(fontproperties='Times New Roman',fontsize=12)\n",
    "plt.xlabel('Number of queries',fontproperties='Times New Roman',fontsize=14)\n",
    "plt.ylabel('Performance',fontproperties='Times New Roman',fontsize=14)\n",
    "plt.legend(loc=4,prop='Times New Roman')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845c6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
