{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array,loadtxt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import joblib\n",
    "from sklearn import model_selection,metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,cross_validate\n",
    "from sklearn.metrics import precision_score,accuracy_score,roc_auc_score,recall_score,confusion_matrix,f1_score,mean_absolute_error\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "from alipy import ToolBox\n",
    "import alipy\n",
    "from alipy.query_strategy import QueryInstanceGraphDensity,QueryInstanceDensityWeighted, QueryInstanceUncertainty\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stmodel(num):\n",
    "    sclf = RandomForestClassifier(oob_score=True,n_jobs=-1)\n",
    "    sxgb = XGBClassifier(eval_metric=['logloss','auc','error'],max_depth=12,n_jobs=-1)\n",
    "    sgnb = GaussianNB()\n",
    "    pipe1 = make_pipeline(ColumnSelector(cols=range(num)),sclf)\n",
    "\n",
    "    pipe2 = make_pipeline(ColumnSelector(cols=range(num)),sxgb)\n",
    "\n",
    "    pipe3 = make_pipeline(ColumnSelector(cols=range(num)),sgnb)\n",
    "\n",
    "    stack = StackingClassifier(classifiers=[pipe1,pipe2,pipe3], meta_classifier=LogisticRegression(solver=\"lbfgs\",class_weight = 'balanced'))\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d7afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.loadtxt('reduction50.csv')\n",
    "y = np.loadtxt('y_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80537347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you would like to run it quickly, please excute the following code:\n",
    "n = 10 # The value of n is determined by you\n",
    "X=X[0:40000:n,:]\n",
    "y = y[0:40000:n]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083aa022",
   "metadata": {},
   "source": [
    "# LAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9326c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alibox = ToolBox(X=X, y=y, query_type='AllLabels', saving_path='...')\n",
    "            \n",
    "# Split data\n",
    "alibox.split_AL(test_ratio=0.3, initial_label_rate=0.01, split_count=20)\n",
    "\n",
    "# Use the default Logistic Regression classifier\n",
    "#model = alibox.get_default_model()\n",
    "model  = stmodel(50)\n",
    "\n",
    "# The cost budget is 50 times querying\n",
    "stopping_criterion = alibox.get_stopping_criterion('num_of_queries', 100)\n",
    "\n",
    "def main_loop(alibox, strategy, round):\n",
    "    # Get the data split of one fold experiment\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox.get_split(round)\n",
    "    # Get intermediate results saver for one fold experiment\n",
    "    saver = alibox.get_stateio(round)\n",
    "\n",
    "    # Set initial performance point\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = alibox.calc_performance_metric(y_true=y[test_idx],\n",
    "                                              y_pred=pred,\n",
    "                                              performance_metric='accuracy_score')\n",
    "    saver.set_initial_point(accuracy)\n",
    "            \n",
    "    # If the stopping criterion is simple, such as query 50 times. Use `for i in range(50):` is ok.\n",
    "    while not stopping_criterion.is_stop():\n",
    "    # Select a subset of Uind according to the query strategy\n",
    "    # Passing model=None to use the default model for evaluating the committees' disagreement\n",
    "        select_ind = strategy.select(label_index=label_ind, unlabel_index=unlab_ind, batch_size=1)\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "\n",
    "        # Update model and calc performance according to the model you are using\n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = alibox.calc_performance_metric(y_true=y[test_idx],\n",
    "                                                y_pred=pred,\n",
    "                                                performance_metric='accuracy_score')\n",
    "\n",
    "        # Save intermediate results to file\n",
    "        st = alibox.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "\n",
    "        # Passing the current progress to stopping criterion object\n",
    "        stopping_criterion.update_information(saver)\n",
    "    # Reset the progress in stopping criterion object\n",
    "    stopping_criterion.reset()\n",
    "    return saver    \n",
    "lal_result = []\n",
    "#density_result = []\n",
    "\n",
    "            \n",
    "for round in range(10):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox.get_split(round)\n",
    "            \n",
    "# Use pre-defined strategy\n",
    "    lal = alibox.get_query_strategy(strategy_name=\"QueryInstanceLAL\")\n",
    "    lal.download_data()\n",
    "    lal.train_selector_from_file(reg_est=5, reg_depth=3)\n",
    "    lal_result.append(copy.deepcopy(main_loop(alibox, lal, round)))\n",
    "\n",
    "analyser = alibox.get_experiment_analyser(x_axis='num_of_queries')\n",
    "analyser.add_method(method_name='LAL', method_results=lal_result)\n",
    "print(analyser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c4a945",
   "metadata": {},
   "source": [
    "# QUIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aliboxq = ToolBox(X=X, y=y, query_type='AllLabels', saving_path='...')           \n",
    "# Split data\n",
    "aliboxq.split_AL(test_ratio=0.3, initial_label_rate=0.01, split_count=20)\n",
    "\n",
    "model  = stmodel(50)\n",
    "            \n",
    "stopping_criterion = aliboxq.get_stopping_criterion('num_of_queries', 100)\n",
    "\n",
    "def main_loop(aliboxq, strategy, round):\n",
    "    # Get the data split of one fold experiment\n",
    "    train_idx, test_idx, label_ind, unlab_ind = aliboxq.get_split(round)\n",
    "    # Get intermediate results saver for one fold experiment\n",
    "    saver = aliboxq.get_stateio(round)\n",
    "\n",
    "    # Set initial performance point\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = aliboxq.calc_performance_metric(y_true=y[test_idx],\n",
    "                                              y_pred=pred,\n",
    "                                              performance_metric='accuracy_score')\n",
    "    print('initial acc:',accuracy)\n",
    "    saver.set_initial_point(accuracy)\n",
    "            \n",
    "\n",
    "    while not stopping_criterion.is_stop():\n",
    "        # Select a subset of Uind according to the query strategy\n",
    "        # Passing model=None to use the default model for evaluating the committees' disagreement\n",
    "        select_ind = strategy.select(label_index=label_ind, unlabel_index=unlab_ind, batch_size=1)\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "\n",
    "        # Update model and calc performance according to the model you are using\n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = aliboxq.calc_performance_metric(y_true=y[test_idx],\n",
    "                                                y_pred=pred,\n",
    "                                                performance_metric='accuracy_score')\n",
    "        \n",
    "        # Save intermediate results to file\n",
    "        st = aliboxq.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "\n",
    "        # Passing the current progress to stopping criterion object\n",
    "        stopping_criterion.update_information(saver)\n",
    "    # Reset the progress in stopping criterion object\n",
    "    stopping_criterion.reset()\n",
    "    return saver    \n",
    "quire_result = []\n",
    "       \n",
    "for round in range(5):\n",
    "    train_idx, test_idx, label_ind, unlab_ind = aliboxq.get_split(round)          \n",
    "    quire = aliboxq.get_query_strategy(strategy_name=\"QueryInstanceQUIRE\",train_idx=train_idx, kernel='linear')\n",
    "    quire_result.append(copy.deepcopy(main_loop(aliboxq,quire, round)))\n",
    "\n",
    "analyserq = aliboxq.get_experiment_analyser(x_axis='num_of_queries')\n",
    "analyserq.add_method(method_name='QUIRE', method_results=quire_result)\n",
    "print(analyserq)\n",
    "analyserq.plot_learning_curves(title='QUIRE', std_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c2f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
